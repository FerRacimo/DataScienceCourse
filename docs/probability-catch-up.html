<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Probability Catch-up | Data Analysis and Statistical Thinking: An R Workbook</title>
  <meta name="description" content="This is a guide for the Globe Data Science Course." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Probability Catch-up | Data Analysis and Statistical Thinking: An R Workbook" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a guide for the Globe Data Science Course." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Probability Catch-up | Data Analysis and Statistical Thinking: An R Workbook" />
  
  <meta name="twitter:description" content="This is a guide for the Globe Data Science Course." />
  

<meta name="author" content="Fernando Racimo, Shyam Gopalakrishnan" />


<meta name="date" content="2021-05-04" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="probability-part-2.html"/>
<link rel="next" href="linear-models.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Analysis and Statistical Thinking</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Getting Started with Data Analysis</a></li>
<li class="chapter" data-level="3" data-path="prob1.html"><a href="prob1.html"><i class="fa fa-check"></i><b>3</b> Probability Part 1</a>
<ul>
<li class="chapter" data-level="3.1" data-path="prob1.html"><a href="prob1.html#todays-programme"><i class="fa fa-check"></i><b>3.1</b> Today’s programme</a></li>
<li class="chapter" data-level="3.2" data-path="prob1.html"><a href="prob1.html#the-bernoulli-distribution-tossing-a-coin"><i class="fa fa-check"></i><b>3.2</b> The Bernoulli distribution: tossing a coin</a></li>
<li class="chapter" data-level="3.3" data-path="prob1.html"><a href="prob1.html#adding-up-coin-tosses"><i class="fa fa-check"></i><b>3.3</b> Adding up coin tosses</a></li>
<li class="chapter" data-level="3.4" data-path="prob1.html"><a href="prob1.html#the-expectation"><i class="fa fa-check"></i><b>3.4</b> The expectation</a></li>
<li class="chapter" data-level="3.5" data-path="prob1.html"><a href="prob1.html#our-first-probability-mass-function"><i class="fa fa-check"></i><b>3.5</b> Our first probability mass function</a></li>
<li class="chapter" data-level="3.6" data-path="prob1.html"><a href="prob1.html#the-variance"><i class="fa fa-check"></i><b>3.6</b> The variance</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="probability-part-2.html"><a href="probability-part-2.html"><i class="fa fa-check"></i><b>4</b> Probability Part 2</a></li>
<li class="chapter" data-level="5" data-path="probability-catch-up.html"><a href="probability-catch-up.html"><i class="fa fa-check"></i><b>5</b> Probability Catch-up</a>
<ul>
<li class="chapter" data-level="5.1" data-path="probability-catch-up.html"><a href="probability-catch-up.html#discrete-distributions"><i class="fa fa-check"></i><b>5.1</b> Discrete distributions</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="probability-catch-up.html"><a href="probability-catch-up.html#poisson-distribution"><i class="fa fa-check"></i><b>5.1.1</b> Poisson distribution</a></li>
<li class="chapter" data-level="5.1.2" data-path="probability-catch-up.html"><a href="probability-catch-up.html#geometric-distribution"><i class="fa fa-check"></i><b>5.1.2</b> Geometric distribution</a></li>
<li class="chapter" data-level="5.1.3" data-path="probability-catch-up.html"><a href="probability-catch-up.html#sampling-from-arbitrary-distributions"><i class="fa fa-check"></i><b>5.1.3</b> Sampling from arbitrary distributions</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="probability-catch-up.html"><a href="probability-catch-up.html#the-normal-distribution-and-the-central-limit-theorem"><i class="fa fa-check"></i><b>5.2</b> The Normal distribution and the Central Limit Theorem</a></li>
<li class="chapter" data-level="5.3" data-path="probability-catch-up.html"><a href="probability-catch-up.html#the-exponential-distribution"><i class="fa fa-check"></i><b>5.3</b> The exponential distribution</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linear-models.html"><a href="linear-models.html"><i class="fa fa-check"></i><b>6</b> Linear Models</a>
<ul>
<li class="chapter" data-level="6.1" data-path="linear-models.html"><a href="linear-models.html#fitting-a-simple-linear-regression"><i class="fa fa-check"></i><b>6.1</b> Fitting a simple linear regression</a></li>
<li class="chapter" data-level="6.2" data-path="linear-models.html"><a href="linear-models.html#interpreting-a-simple-linear-regression"><i class="fa fa-check"></i><b>6.2</b> Interpreting a simple linear regression</a></li>
<li class="chapter" data-level="6.3" data-path="linear-models.html"><a href="linear-models.html#simulating-data-from-a-linear-model"><i class="fa fa-check"></i><b>6.3</b> Simulating data from a linear model</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="properties-of-estimators-and-hypothesis-testing.html"><a href="properties-of-estimators-and-hypothesis-testing.html"><i class="fa fa-check"></i><b>7</b> Properties of Estimators and Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="7.1" data-path="properties-of-estimators-and-hypothesis-testing.html"><a href="properties-of-estimators-and-hypothesis-testing.html#properties-of-point-estimators"><i class="fa fa-check"></i><b>7.1</b> Properties of point estimators</a></li>
<li class="chapter" data-level="7.2" data-path="properties-of-estimators-and-hypothesis-testing.html"><a href="properties-of-estimators-and-hypothesis-testing.html#obtaining-confidence-intervals"><i class="fa fa-check"></i><b>7.2</b> Obtaining confidence intervals</a></li>
<li class="chapter" data-level="7.3" data-path="properties-of-estimators-and-hypothesis-testing.html"><a href="properties-of-estimators-and-hypothesis-testing.html#hypothesis-testing"><i class="fa fa-check"></i><b>7.3</b> Hypothesis testing</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="likelihood-based-inference.html"><a href="likelihood-based-inference.html"><i class="fa fa-check"></i><b>8</b> Likelihood-based inference</a>
<ul>
<li class="chapter" data-level="8.1" data-path="likelihood-based-inference.html"><a href="likelihood-based-inference.html#meteorite-data"><i class="fa fa-check"></i><b>8.1</b> Meteorite data</a></li>
<li class="chapter" data-level="8.2" data-path="likelihood-based-inference.html"><a href="likelihood-based-inference.html#simple-linear-regression"><i class="fa fa-check"></i><b>8.2</b> Simple linear regression</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="bayesian-inference.html"><a href="bayesian-inference.html"><i class="fa fa-check"></i><b>9</b> Bayesian Inference</a>
<ul>
<li class="chapter" data-level="9.1" data-path="bayesian-inference.html"><a href="bayesian-inference.html#using-bayes-rule-covid-19"><i class="fa fa-check"></i><b>9.1</b> Using Bayes’ rule: Covid-19</a></li>
<li class="chapter" data-level="9.2" data-path="bayesian-inference.html"><a href="bayesian-inference.html#first-foray-into-bayesian-inference"><i class="fa fa-check"></i><b>9.2</b> First foray into Bayesian inference</a></li>
<li class="chapter" data-level="9.3" data-path="bayesian-inference.html"><a href="bayesian-inference.html#conjugate-prior-rejection-sampling-and-mcmc"><i class="fa fa-check"></i><b>9.3</b> Conjugate prior, Rejection sampling and MCMC*</a></li>
<li class="chapter" data-level="9.4" data-path="bayesian-inference.html"><a href="bayesian-inference.html#bayesian-point-estimates-and-credible-intervals"><i class="fa fa-check"></i><b>9.4</b> Bayesian point estimates and credible intervals</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="bayesian-inference.html"><a href="bayesian-inference.html#point-estimates"><i class="fa fa-check"></i><b>9.4.1</b> Point estimates</a></li>
<li class="chapter" data-level="9.4.2" data-path="bayesian-inference.html"><a href="bayesian-inference.html#credible-intervals"><i class="fa fa-check"></i><b>9.4.2</b> Credible intervals</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>10</b> Classification</a></li>
<li class="chapter" data-level="11" data-path="model-assessment.html"><a href="model-assessment.html"><i class="fa fa-check"></i><b>11</b> Model Assessment</a></li>
<li class="chapter" data-level="12" data-path="resampling.html"><a href="resampling.html"><i class="fa fa-check"></i><b>12</b> Resampling</a>
<ul>
<li class="chapter" data-level="12.1" data-path="resampling.html"><a href="resampling.html#the-bootstrap"><i class="fa fa-check"></i><b>12.1</b> The bootstrap</a></li>
<li class="chapter" data-level="12.2" data-path="resampling.html"><a href="resampling.html#permutation-test"><i class="fa fa-check"></i><b>12.2</b> Permutation test</a></li>
<li class="chapter" data-level="12.3" data-path="resampling.html"><a href="resampling.html#validation"><i class="fa fa-check"></i><b>12.3</b> Validation</a></li>
<li class="chapter" data-level="12.4" data-path="resampling.html"><a href="resampling.html#cross-validation"><i class="fa fa-check"></i><b>12.4</b> Cross-validation</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="mixed-models.html"><a href="mixed-models.html"><i class="fa fa-check"></i><b>13</b> Mixed Models</a></li>
<li class="chapter" data-level="14" data-path="ordination.html"><a href="ordination.html"><i class="fa fa-check"></i><b>14</b> Ordination</a>
<ul>
<li class="chapter" data-level="14.1" data-path="ordination.html"><a href="ordination.html#libraries-and-data"><i class="fa fa-check"></i><b>14.1</b> Libraries and Data</a></li>
<li class="chapter" data-level="14.2" data-path="ordination.html"><a href="ordination.html#principal-component-analysis-pca"><i class="fa fa-check"></i><b>14.2</b> Principal component analysis (PCA)</a></li>
<li class="chapter" data-level="14.3" data-path="ordination.html"><a href="ordination.html#pca-under-the-hood"><i class="fa fa-check"></i><b>14.3</b> PCA under the hood</a></li>
<li class="chapter" data-level="14.4" data-path="ordination.html"><a href="ordination.html#principal-components-as-explanatory-variables"><i class="fa fa-check"></i><b>14.4</b> Principal components as explanatory variables</a></li>
<li class="chapter" data-level="14.5" data-path="ordination.html"><a href="ordination.html#nmds"><i class="fa fa-check"></i><b>14.5</b> NMDS</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>15</b> Clustering</a>
<ul>
<li class="chapter" data-level="15.1" data-path="clustering.html"><a href="clustering.html#libraries-and-data-1"><i class="fa fa-check"></i><b>15.1</b> Libraries and Data</a></li>
<li class="chapter" data-level="15.2" data-path="clustering.html"><a href="clustering.html#distances"><i class="fa fa-check"></i><b>15.2</b> Distances</a></li>
<li class="chapter" data-level="15.3" data-path="clustering.html"><a href="clustering.html#k-means-clustering"><i class="fa fa-check"></i><b>15.3</b> K-means clustering</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="recostats-linear-models.html"><a href="recostats-linear-models.html"><i class="fa fa-check"></i><b>16</b> REcoStats: Linear Models</a>
<ul>
<li class="chapter" data-level="16.1" data-path="recostats-linear-models.html"><a href="recostats-linear-models.html#fitting-a-simple-linear-regression-1"><i class="fa fa-check"></i><b>16.1</b> Fitting a simple linear regression</a></li>
<li class="chapter" data-level="16.2" data-path="recostats-linear-models.html"><a href="recostats-linear-models.html#interpreting-a-simple-linear-regression-1"><i class="fa fa-check"></i><b>16.2</b> Interpreting a simple linear regression</a></li>
<li class="chapter" data-level="16.3" data-path="recostats-linear-models.html"><a href="recostats-linear-models.html#simulating-data-from-a-linear-model-1"><i class="fa fa-check"></i><b>16.3</b> Simulating data from a linear model</a></li>
<li class="chapter" data-level="16.4" data-path="recostats-linear-models.html"><a href="recostats-linear-models.html#hypothesis-testing-and-permutation-testing"><i class="fa fa-check"></i><b>16.4</b> Hypothesis testing and permutation testing</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Analysis and Statistical Thinking: An R Workbook</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="probability-catch-up" class="section level1" number="5">
<h1><span class="header-section-number">Chapter 5</span> Probability Catch-up</h1>
<div id="discrete-distributions" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Discrete distributions</h2>
<p>We’ll start by reviewing a few commonly used discrete probability distributions.</p>
<p>There is a whole world of R functions we can use to sample random values from probability distributions or obtain probabilities from them. Generally, each of these functions is referenced with an abbreviation (<code>pois</code> for Poisson, <code>geom</code> for Geometric, <code>binom</code> for the Binomial, etc.) preceded by the type of function we want, referenced by a letter:</p>
<ul>
<li><code>r</code>… for simulating from a distribution of interest</li>
<li><code>d</code>… for obtaining the probability mass function <span class="math inline">\(P[X=x]\)</span> (or probability density function for continuous random variables)</li>
<li><code>p</code>… for obtaining the cumulative distribution function, which is just a fancy way of saying <span class="math inline">\(P[X \leq q]\)</span> for any value of <span class="math inline">\(q\)</span>.</li>
<li><code>q</code>… for the quantile function of a distribution of interest</li>
</ul>
<p>For example, in the case of the Poisson distribution:</p>
<ul>
<li><code>rpois(n, lambda)</code> generates <span class="math inline">\(n\)</span> random samples from the Poisson distribution with rate <code>lambda</code></li>
<li><code>dpois(x, lambda)</code> allow us to calculate the Poisson probability mass function (PMF) <span class="math inline">\(P[X=x] = \lambda^x e^{-\lambda}/x!\)</span> for a given value of <span class="math inline">\(x\)</span> (an integer) and <code>lambda</code> (<span class="math inline">\(\lambda\)</span>) - the rate of the Poisson process.</li>
<li><code>ppois(q,lambda)</code> allow us to calculate the Poisson cumulative distribution function <span class="math inline">\(P[X \leq q]\)</span> for any value of <span class="math inline">\(q\)</span> (an integer) and rate <code>lambda</code> (<span class="math inline">\(\lambda\)</span>).</li>
<li><code>qpois(p, lambda)</code> provides the <span class="math inline">\(p\)</span>th quantile of the Poisson PMF with rate <code>lambda</code>.</li>
</ul>
<p>The internet and the R help functions (e.g. <code>?rpois</code>) are your friends here. Use them whenever you’re interested in understanding how to use these functions, and what types of inputs they require.</p>
<div id="poisson-distribution" class="section level3" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Poisson distribution</h3>
<p>Let’s take a stab at answering some discrete probability questions using the Poisson distribution and the above mentioned functions.</p>
<p>Recall that the Poisson distribution is used to model the number of events (or objects) that occur over a given period of time (or space), if these occur with a constant mean rate and independently of each other. It is generally applied to systems with a large number of possible events, each of which is rare.</p>
<p>Some (simplified) examples include:</p>
<ul>
<li><p>Number of rain droplets falling on a house roof</p></li>
<li><p>Number of meteorites hitting a planet over a given period of time</p></li>
<li><p>Number of buses arriving at a station over a given period of time</p></li>
<li><p>Number of trees in a given area of land</p></li>
<li><p>Number of fish in a given volume of water</p></li>
</ul>
<p>Here are plots of Poisson PMFs with different mean rates <span class="math inline">\(\lambda\)</span>:</p>
<p><img src="DataScience_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p><strong>Exercise</strong>: Let’s assume the number of trees on any squared kilometer of land follows a Poisson distribution. If trees occur at a mean rate of 5 per squared kilometer, what is the probability that <strong>3 or less trees</strong> will occur on a given squared kilometer?</p>
<p>A nice property of the Poisson distribution is that if its rate <span class="math inline">\(\lambda\)</span> is given over a particular unit of time (or space), but our period or area of study is larger or smaller than that unit, we can simply multiply that rate by the extent of the corresponding period or area to get the rate of the Poisson distribution for that period or area:</p>
<p><span class="math display">\[P[ x\ events\ in\ interval\ of\ length\ 1] =  \lambda^x e^{-\lambda}/x!\]</span></p>
<p><span class="math display">\[P[ x\ events\ in\ interval\ of\ length\ t] =  (\lambda t)^x e^{-\lambda t}/x!\]</span></p>
<p><strong>Exercise</strong>: Given the same per-unit rate as the previous exercise, what is the probability that <strong>more than 10 trees</strong> will occur on area that is <strong>3 squared kilometers</strong> large?</p>
</div>
<div id="geometric-distribution" class="section level3" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Geometric distribution</h3>
<p>Another interesting distribution is the Geometric distribution. Recall that this distribution serves to model a sequence of trials, in which we are interested in computing the probability of a given number of failures, before we are succesful. The probability mass function depends on a single parameter, the per-trial probability of success, <code>p</code>. The probability I fail <code>k</code> times before I succeed is:</p>
<p><span class="math display">\[P[X = k] = (1-p)^k p \]</span></p>
<p>Here are plots of Geometric PMFs with different probabilities of success:</p>
<p><img src="DataScience_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>While the probability mass function always decreases for increasing number of failures, the rate of this decrease strongly depends on the probability of success in eahc trial. For example, if I have a loaded coin that has 90% of probability of giving heads, then I won’t have to wait for long until I get heads (success). Looking at the bottom left panel in the figures above, I can see that it’s actually most likely I will get heads on the first try.</p>
<p><strong>Exercise</strong>: I have a loaded coin that I use to trick people. Unlike normal coins, this coin results in heads 3 out of 4 times, on average. I start tossing the coin, and wonder: what is the probability I get at least 2 tails before I get a head? And what is the probability I get exactly 2 tails before I get a head? Use the geometric cumulative distribution function <code>pgeom</code> and the probability mass function <code>dgeom</code>, respectively, to answer these questions.</p>
</div>
<div id="sampling-from-arbitrary-distributions" class="section level3" number="5.1.3">
<h3><span class="header-section-number">5.1.3</span> Sampling from arbitrary distributions</h3>
<p>What if we want to create our own probability distribution? In R, we can, using the funciton <code>sample()</code>. Here’s an example of a probability distribution I just decided to create, which serves to model a six-sided dice roll, where each side has equal probability (1/6) of being obtained:</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="probability-catch-up.html#cb36-1" aria-hidden="true" tabindex="-1"></a>sides<span class="ot">=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>) <span class="co"># vector of elements</span></span>
<span id="cb36-2"><a href="probability-catch-up.html#cb36-2" aria-hidden="true" tabindex="-1"></a>probabilities<span class="ot">=</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">6</span>,<span class="dv">1</span><span class="sc">/</span><span class="dv">6</span>,<span class="dv">1</span><span class="sc">/</span><span class="dv">6</span>,<span class="dv">1</span><span class="sc">/</span><span class="dv">6</span>,<span class="dv">1</span><span class="sc">/</span><span class="dv">6</span>,<span class="dv">1</span><span class="sc">/</span><span class="dv">6</span>) <span class="co"># vector of probabilities for each element</span></span>
<span id="cb36-3"><a href="probability-catch-up.html#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="fu">sample</span>(sides,<span class="dv">10</span>,<span class="at">prob=</span>probabilities,<span class="at">replace=</span><span class="cn">TRUE</span>) <span class="co"># roll a dice 10 times</span></span></code></pre></div>
<pre><code>##  [1] 6 2 5 5 3 6 5 5 2 3</code></pre>
<p>The option <code>replace=TRUE</code> ensures we can sample <strong>with replacement</strong> from the <code>sides</code> vector. Because each element has equal probability of occurring, the above is also calle a <strong>discrete uniform distribution</strong>. This is not necessary, however. Here’s an example in which we roll a loaded dice where the side <code>6</code> is biased to appear more frequently than the others:</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="probability-catch-up.html#cb38-1" aria-hidden="true" tabindex="-1"></a>sides<span class="ot">=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>) <span class="co"># vector of elements</span></span>
<span id="cb38-2"><a href="probability-catch-up.html#cb38-2" aria-hidden="true" tabindex="-1"></a>weights<span class="ot">=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">4</span>) <span class="co"># vector of unnormalized weights for each element, with the element &#39;6&#39; being more favored than the others</span></span>
<span id="cb38-3"><a href="probability-catch-up.html#cb38-3" aria-hidden="true" tabindex="-1"></a>probabilities <span class="ot">=</span> weights <span class="sc">/</span> <span class="fu">sum</span>(weights) <span class="co"># to create a probability vector, we ensure all the weights sum up to 1</span></span>
<span id="cb38-4"><a href="probability-catch-up.html#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="fu">sample</span>(sides,<span class="dv">10</span>,<span class="at">prob=</span>probabilities,<span class="at">replace=</span><span class="cn">TRUE</span>) <span class="co"># roll a loaded dice 10 times</span></span></code></pre></div>
<pre><code>##  [1] 5 6 5 6 3 6 6 6 6 6</code></pre>
<p>Let’s put this function into practice.</p>
<p><strong>Exercise</strong>: You’re a dog breeder who’s been given the following table of litter size frequencies, obtained from 10,000 previously recorded litter sizes:</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="probability-catch-up.html#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(knitr)</span>
<span id="cb40-2"><a href="probability-catch-up.html#cb40-2" aria-hidden="true" tabindex="-1"></a>dogprobs <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">c</span>(<span class="fu">dpois</span>(<span class="fu">seq</span>(<span class="dv">1</span>,<span class="dv">9</span>),<span class="dv">4</span>)),<span class="dv">2</span>)</span>
<span id="cb40-3"><a href="probability-catch-up.html#cb40-3" aria-hidden="true" tabindex="-1"></a>dogprobs <span class="ot">&lt;-</span> <span class="fu">c</span>(dogprobs, <span class="dv">1</span><span class="sc">-</span><span class="fu">sum</span>(dogprobs))</span>
<span id="cb40-4"><a href="probability-catch-up.html#cb40-4" aria-hidden="true" tabindex="-1"></a>littertab <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>,<span class="dv">10</span>),dogprobs)</span>
<span id="cb40-5"><a href="probability-catch-up.html#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(littertab) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;litter_size&quot;</span>,<span class="st">&quot;frequency&quot;</span>)</span>
<span id="cb40-6"><a href="probability-catch-up.html#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="fu">kable</span>(littertab,<span class="at">caption=</span><span class="st">&quot;Dog litter size frequencies&quot;</span>)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-24">Table 5.1: </span>Dog litter size frequencies</caption>
<thead>
<tr class="header">
<th align="right">litter_size</th>
<th align="right">frequency</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">0.07</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">0.15</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">0.20</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">0.20</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">0.16</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">0.10</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">0.06</td>
</tr>
<tr class="even">
<td align="right">8</td>
<td align="right">0.03</td>
</tr>
<tr class="odd">
<td align="right">9</td>
<td align="right">0.01</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">0.02</td>
</tr>
</tbody>
</table>
<p>In this exercise, we’ll assume that the probability of a litter size of 11 or higher is effectively zero. Simulate 100 new litter sizes using the above table as an approximation to the true distribution of litter sizes, by using the recorded frequencies as probabilities.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Compute the sample mean, sample variance and create a histogram (with the function <code>hist()</code>) of the simulated litter sizes.</p></li>
<li><p>Estimate the probability mass function of your simulated samples from part (a), using the help of the function <code>table()</code>. This should be very similar to the original probabilities that you simulated from.</p></li>
</ol>
</div>
</div>
<div id="the-normal-distribution-and-the-central-limit-theorem" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> The Normal distribution and the Central Limit Theorem</h2>
<p>The Central Limit Theorem states that if <span class="math inline">\(X_1, X_2, ..., X_m\)</span> are random samples from a distribution (any distribution) with mean <span class="math inline">\(\mu\)</span> and finite variance <span class="math inline">\(\sigma^2\)</span>, and the sample mean is <span class="math inline">\(\bar{X}\)</span>, then, as m grows large, <span class="math inline">\(\bar{X}\)</span> converges in distribution to a Normal distribution with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sqrt{\sigma^2 /m}\)</span>.</p>
<p>In other words, for large values of m (large sample sizes), we can treat the average of our sample as being drawn from <span class="math inline">\(N(\mu,\sigma^2/m)\)</span>.</p>
<p>How can we verify this to be true? Well, one way to do this is to pretend (simulate) we have many sample sets, each composed of a large number of samples, compute their sample mean, and look at the histogram over all the sample means. If the CLT holds, that histogram should look very similar to a Normal distribution. Let’s try that here!</p>
<p>We’ll begin with a binomial distribution as our initial “sampling” distribution. We can, for example, draw <span class="math inline">\(m=100\)</span> values from a binomial distribution with parameters <span class="math inline">\([p=0.7,n=5]\)</span>, and then compute their mean:</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="probability-catch-up.html#cb41-1" aria-hidden="true" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="dv">100</span> <span class="co"># sample size</span></span>
<span id="cb41-2"><a href="probability-catch-up.html#cb41-2" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fl">0.7</span> <span class="co"># binomial success parameter</span></span>
<span id="cb41-3"><a href="probability-catch-up.html#cb41-3" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">5</span> <span class="co"># binomial size parameter</span></span>
<span id="cb41-4"><a href="probability-catch-up.html#cb41-4" aria-hidden="true" tabindex="-1"></a>samp1 <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(m,n,p)  <span class="co"># simulation</span></span>
<span id="cb41-5"><a href="probability-catch-up.html#cb41-5" aria-hidden="true" tabindex="-1"></a>mean1 <span class="ot">&lt;-</span> <span class="fu">mean</span>(samp1) <span class="co"># sample average</span></span></code></pre></div>
<p>The CLT theorem is a statement about multiple means from multiple samples, so let’s repeat the above exercise 1,000 times:</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="probability-catch-up.html#cb42-1" aria-hidden="true" tabindex="-1"></a>allmeans <span class="ot">&lt;-</span> <span class="fu">sapply</span>(<span class="fu">seq</span>(<span class="dv">1</span>,<span class="dv">1000</span>), <span class="cf">function</span>(i){<span class="fu">mean</span>(<span class="fu">rbinom</span>(m,n,p))})</span>
<span id="cb42-2"><a href="probability-catch-up.html#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(allmeans,<span class="at">freq=</span><span class="cn">FALSE</span>,<span class="at">main=</span><span class="st">&quot;Histogram of sample means&quot;</span>)</span></code></pre></div>
<p><img src="DataScience_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p>The CLT states that this distribution should be very close to a Normal distribution with mean <span class="math inline">\(\mu = np = 5*0.7 = 3.5\)</span> and <span class="math inline">\(\sigma^2 = (np(1-p))/m = 5*0.7*0.3/100 = 0.0105\)</span>. Let’s verify that:</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="probability-catch-up.html#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(allmeans,<span class="at">freq=</span><span class="cn">FALSE</span>,<span class="at">main=</span><span class="st">&quot;Histogram of sample means&quot;</span>) <span class="co"># Histogram of sample means</span></span>
<span id="cb43-2"><a href="probability-catch-up.html#cb43-2" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> n<span class="sc">*</span>p <span class="co"># mean of Normal distribution under the CLT</span></span>
<span id="cb43-3"><a href="probability-catch-up.html#cb43-3" aria-hidden="true" tabindex="-1"></a>var <span class="ot">&lt;-</span> n<span class="sc">*</span>p<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>p)<span class="sc">/</span>m <span class="co"># variance of Normal distribution under the CLT</span></span>
<span id="cb43-4"><a href="probability-catch-up.html#cb43-4" aria-hidden="true" tabindex="-1"></a>sd <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(var) <span class="co"># standard deviation of Normal distribution under the CLT</span></span>
<span id="cb43-5"><a href="probability-catch-up.html#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dnorm</span>(x,<span class="at">mean=</span>mu,<span class="at">sd=</span>sd),<span class="at">from=</span><span class="sc">-</span><span class="dv">5</span>,<span class="at">to=</span><span class="dv">5</span>,<span class="at">n=</span><span class="dv">5000</span>,<span class="at">add=</span><span class="cn">TRUE</span>,<span class="at">col=</span><span class="st">&quot;red&quot;</span>) <span class="co"># Normal distribution</span></span></code></pre></div>
<p><img src="DataScience_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<p><strong>Exercise</strong>: Repeat the exercise above but instead of a binomial
distribution, use a Poisson distribution with parameter <span class="math inline">\(\lambda=5\)</span> (considering what the mean and variance of the corresponding Normal distribution should be).</p>
<p><strong>Exercise</strong>: Repeat the exercise above but instead of a binomial distribution, use a Geometric distribution with parameter <span class="math inline">\(p=0.8\)</span> (considering what the mean and variance of the corresponding Normal distribution should be).</p>
<p><strong>Note</strong>: if you know <em>a priori</em> that <span class="math inline">\(X_1, X_2, ..., X_m\)</span> are independent draws from a <span class="math inline">\(Normal(\mu,\sigma^2)\)</span> distribution, then you don’t need to invoke the CLT: <span class="math inline">\(\bar{X}\)</span> will be normally distributed with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sqrt{\sigma^2 /m}\)</span>, even for low values of <span class="math inline">\(m\)</span>!</p>
</div>
<div id="the-exponential-distribution" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> The exponential distribution</h2>
<p>Previously, we simulated the <em>quantity</em> of buses that would randomly arrive at a station over a particular period of time (an hour), given that the <em>rate</em> of this process is constant. For this, we used the Poisson distribution with parameter <span class="math inline">\(\lambda\)</span> equal to this rate. Using the same rate assumption, we can also model the <em>waiting time</em> until the next bus arrives, using the exponential distribution. Take a look at the help page for <code>?rexp</code>.</p>
<p><strong>Exercise</strong>: Buses arrive at a station at an average rate of 3 per hour. Using the <code>rexp</code> function, simulate 1,000 waiting times (in hours) of this random process, assuming the waiting time follows an exponential distribution. Create a histogram of these waiting times. Then, calculate their sample mean and compare it to the expected value of an exponential distribution with rate 3.</p>
<p><strong>Exercise</strong>: I’ve arrived at a station. Assuming the same rate as above, use the <code>pexp</code> function to obtain the probability that I will have to wait less than 15 minutes till the next bus arrives.</p>
<p><strong>Exercise</strong>: Assuming the same rate as above, use the <code>pexp</code> function to obtain the probability that I will have to wait more than 30 minutes till the next bus arrives.</p>
<p><strong>Exercise</strong>: Assuming the same rate as above, use the <code>pexp</code> function to obtain the probability that I will have to wait between 33 and 48 minutes for the next bus to arrive.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="probability-part-2.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="linear-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["DataScience.pdf", "DataScience.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
